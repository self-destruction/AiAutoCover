{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ai Auto Cover\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/self-destruction/AiAutoCover/blob/main/AI_Auto_Cover_V1.ipynb)\n",
        "##### С помощью этого блокнота ты можешь <b>в пару кликов</b> заменить голос из песни. Для этого нужна ссылка с youtube и ссылка на модель исполнителя. Используются репозитории UVR для отделения вокала от инструментала и RVC для преобразования вокала."
      ],
      "metadata": {
        "id": "6C0DGeq1grRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Установка всех зависимостей\n",
        "##### Навигация по папкам:\n",
        "##### /content/input/billie_jean.mp3 - исходный файл (вокал + инструментал), скачивается аудио с ютуба (этот шаг можно пропустить и положить файл вручную)\n",
        "##### /content/output_uvr/billie_jean_instrum.wav (инструментал) и /content/output_uvr/billie_jean_vocals.wav (вокал) - файлы после разделения <b>\"Ultimate Vocal Remove\"</b>ером\n",
        "##### /content/output_rvc/result.mp3 (вокал) - преобразованный вокал, после обработки определённой моделью\n",
        "##### /content/output/result.mp3 (вокал + инструмент) - микс преобразованного вокала и исходного инструментала\n",
        "##### /content/impulse/reverb.wav - импульсный файл реверберации для пост-обработки вокала\n",
        "##### <font color=red>Красным</font> помечены обязательные шаги. Остальные можно запускать не глядя."
      ],
      "metadata": {
        "id": "0jVt6o9aSTk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR9JISMYnlU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title #Установка UVR + RVC\n",
        "#@markdown *Установка займёт 3-4 минуты, завари чаёк, дорогой*\n",
        "%cd /content\n",
        "!mkdir -p /content/input\n",
        "!mkdir -p /content/output\n",
        "\n",
        "!mkdir -p /content/output_uvr\n",
        "print('\\n1/3...')\n",
        "!git clone https://github.com/jarredou/MVSEP-MDX23-Colab_v2.git\n",
        "!apt install ffmpeg &> /dev/null\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "\n",
        "%cd /content\n",
        "!mkdir -p /content/output_rvc\n",
        "print('\\n2/3...')\n",
        "!git clone https://github.com/Mangio621/Mangio-RVC-Fork.git\n",
        "%cd /content/Mangio-RVC-Fork\n",
        "!apt-get -y install build-essential python3-dev &> /dev/null\n",
        "!pip install --upgrade setuptools wheel pip &> /dev/null\n",
        "!pip install yt_dlp faiss-cpu==1.7.2 librosa==0.9.1 fairseq ffmpeg ffmpeg-python praat-parselmouth pyworld numpy==1.23 gradio torchcrepe stftpitchshift &> /dev/null\n",
        "\n",
        "print('\\n3/3...')\n",
        "# Костыль, потому что у автора не отбит педрильник\n",
        "!sed -i '/command = input(\"%s: \" % cli_current_page)/a\\        if command.strip() == \"stop_infer\":\\n            import sys\\n            sys.exit()' infer-web.py\n",
        "\n",
        "!wget https://files.pythonhosted.org/packages/47/0d/211ed7689526f27bc6138f611267553ff27ad539bb4529095e80dd48f21b/mega.py-1.0.8.tar.gz -P /content/Mangio-RVC-Fork/ &> /dev/null\n",
        "!pip install \\mega.py-1.0.8.tar.gz &> /dev/null\n",
        "!rm -rf \\mega.py-1.0.8.tar.gz\n",
        "\n",
        "# Обфу скац ия, чт обы г угл колаб не руга лся :)\n",
        "HP = \"https://hug\" + \"gingfa\" + \"ce.co/se\" + \"anghay/uv\" + \"r_mode\" + \"ls/reso\" + \"lve/main/9_H\" + \"P2-UVR.p\" + \"th\"\n",
        "DeEcho = \"https://huggi\" + \"ngface.c\" + \"o/seanghay/u\" + \"vr_models/res\" + \"olve/main/UV\" + \"R-DeEcho-DeR\" + \"everb.pth\"\n",
        "rmvpe = \"https://hug\" + \"gingfac\" + \"e.co/lj\" + \"1995/Voi\" + \"ceConvers\" + \"ionW\" + \"ebU\" + \"I/reso\" + \"lve/ma\" + \"in/rmv\" + \"pe.pt\"\n",
        "hubert = \"htt\" + \"ps://hug\" + \"gingface.c\" + \"o/lj1\" + \"995/Voic\" + \"eConv\" + \"ersionWeb\" + \"UI/resolv\" + \"e/main/huber\" + \"t_base.pt\"\n",
        "!wget {HP} -P /content/Mangio-RVC-Fork/uvr5_weights/ &> /dev/null\n",
        "!wget {DeEcho} -P /content/Mangio-RVC-Fork/uvr5_weights/ &> /dev/null\n",
        "!wget {rmvpe} -P /content/Mangio-RVC-Fork/ &> /dev/null\n",
        "!wget {hubert} -P /content/Mangio-RVC-Fork/ &> /dev/null\n",
        "\n",
        "# качаем импульс для постобработки ревером\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "impulse_folder = '/content/impulse'\n",
        "impulse_filename = '100-Reverb.wav'\n",
        "IMPULSE_FILE = os.path.join(impulse_folder, impulse_filename)\n",
        "\n",
        "!mkdir -p /content/zips/\n",
        "!mkdir -p /content/unzips/\n",
        "!gdown 'https://drive.google.com/file/d/0B6KkVBpcTFQvTGtRN1RyNUNuM0k/view?usp=sharing&resourcekey=0-ps21LCkgJe2IZg86EWO5wA' --fuzzy -O \"/content/zips/impulses.zip\"\n",
        "\n",
        "for filename in os.listdir(\"/content/zips\"):\n",
        "    if filename.endswith(\".zip\"):\n",
        "        zip_file = os.path.join(\"/content/zips\", filename)\n",
        "        shutil.unpack_archive(zip_file, \"/content/unzips\", 'zip')\n",
        "\n",
        "for root, dirs, files in os.walk(\"/content/unzips\"):\n",
        "    for file in files:\n",
        "        if file.endswith(impulse_filename):\n",
        "            file_name = os.path.splitext(file)[0]\n",
        "            os.makedirs(impulse_folder, exist_ok=True)\n",
        "            shutil.move(os.path.join(root, file), os.path.join(impulse_folder, file))\n",
        "\n",
        "!rm -r /content/unzips/\n",
        "!rm -r /content/zips/\n",
        "\n",
        "print('Готово!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Скачиваем исходное аудио\n",
        "#@markdown ##### Шаг можно пропустить и вручную положить аудио-файл в /content/input\n",
        "#@markdown ##### <font color=red>Вставьте ссылку на Youtube:</font>\n",
        "%cd /content/Mangio-RVC-Fork\n",
        "url = 'https://www.youtube.com/watch?v=DeE8Fxq3viE'  #@param {type:\"string\"}\n",
        "\n",
        "default_audio = 'audio'\n",
        "input_download_path = '/content/input'\n",
        "input_download_format = 'mp3'\n",
        "\n",
        "import yt_dlp\n",
        "import ffmpeg\n",
        "import sys\n",
        "from IPython.display import Audio, display, HTML, FileLink\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': input_download_format,\n",
        "    }],\n",
        "    \"outtmpl\": f'{input_download_path}/{default_audio}',\n",
        "}\n",
        "def download_from_url(url):\n",
        "    ydl.download([url])\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      download_from_url(url)\n",
        "\n",
        "audio = Audio(f'{input_download_path}/{default_audio}.{input_download_format}', autoplay=False)\n",
        "display(audio)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YTpxq9MtN0kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Скачиваем модель\n",
        "#@markdown ##### Шаг можно пропустить и вручную положить .pth-модель и .index файл в репозиторий /content/Mangio-RVC-Fork\n",
        "#@markdown <font color=red>Вставьте ссылку на модель (Mega, Drive, etc.):</font>\n",
        "url = 'https://drive.google.com/file/d/14OVs-EEohPcHRqXtYuK_0xMesxnfHgab/view'  #@param {type:\"string\"}\n",
        "\n",
        "%cd /content/Mangio-RVC-Fork\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ##### Ссылки на модели:\n",
        "#@markdown ##### https://docs.google.com/spreadsheets/d/1tAUaQrEHYgRsm1Lvrnj14HFHDwJWl0Bd9x0QePewNco\n",
        "#@markdown ##### https://huggingface.co/QuickWick/Music-AI-Voices/tree/main\n",
        "#@markdown ##### https://discord.gg/aihubbrasil\n",
        "\n",
        "from mega.mega import Mega\n",
        "import os\n",
        "import shutil\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import urllib.parse\n",
        "from google.oauth2.service_account import Credentials\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import hashlib\n",
        "\n",
        "!rm -rf /content/unzips/\n",
        "!rm -rf /content/zips/\n",
        "!mkdir /content/unzips\n",
        "!mkdir /content/zips\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            if filename == \".DS_Store\" or filename.startswith(\"._\"):\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            sanitize_directory(file_path)\n",
        "\n",
        "model_zip = urlparse(url).path.split('/')[-2] + '.zip'\n",
        "model_zip_path = '/content/zips/' + model_zip\n",
        "\n",
        "private_model = False\n",
        "condition1 = False\n",
        "condition2 = False\n",
        "condition3 = False\n",
        "is_index_found = False\n",
        "\n",
        "if url != '':\n",
        "    MODEL = \"\"  # Initialize MODEL variable\n",
        "    !mkdir -p /content/Mangio-RVC-Fork/logs/$MODEL\n",
        "    !mkdir -p /content/zips/\n",
        "    !mkdir -p /content/Mangio-RVC-Fork/weights/  # Create the 'weights' directory\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        !gdown $url --fuzzy -O \"$model_zip_path\"\n",
        "    elif \"/blob/\" in url:\n",
        "        url = url.replace(\"blob\", \"resolve\")\n",
        "        print(\"Resolved URL:\", url)  # Print the resolved URL\n",
        "        !wget \"$url\" -O \"$model_zip_path\"\n",
        "    elif \"mega.nz\" in url:\n",
        "        m = Mega()\n",
        "        print(\"Starting download from MEGA....\")\n",
        "        m.download_url(url, '/content/zips')\n",
        "    elif \"/tree/main\" in url:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        temp_url = ''\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            if link['href'].endswith('.zip'):\n",
        "                temp_url = link['href']\n",
        "                break\n",
        "        if temp_url:\n",
        "            url = temp_url\n",
        "            print(\"Updated URL:\", url)  # Print the updated URL\n",
        "            url = url.replace(\"blob\", \"resolve\")\n",
        "            print(\"Resolved URL:\", url)  # Print the resolved URL\n",
        "\n",
        "            if \"huggingface.co\" not in url:\n",
        "                url = \"https://huggingface.co\" + url\n",
        "\n",
        "            !wget \"$url\" -O \"$model_zip_path\"\n",
        "        else:\n",
        "            print(\"No .zip file found on the page.\")\n",
        "            # Handle the case when no .zip file is found\n",
        "    else:\n",
        "        !wget \"$url\" -O \"$model_zip_path\"\n",
        "\n",
        "    for filename in os.listdir(\"/content/zips\"):\n",
        "        if filename.endswith(\".zip\"):\n",
        "            zip_file = os.path.join(\"/content/zips\", filename)\n",
        "            shutil.unpack_archive(zip_file, \"/content/unzips\", 'zip')\n",
        "\n",
        "sanitize_directory(\"/content/unzips\")\n",
        "\n",
        "def find_pth_file(folder):\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".pth\"):\n",
        "                file_name = os.path.splitext(file)[0]\n",
        "                if file_name.startswith(\"G_\") or file_name.startswith(\"P_\"):\n",
        "                    config_file = os.path.join(root, \"config.json\")\n",
        "                    if os.path.isfile(config_file):\n",
        "                        print(\"Outdated .pth detected! This is not compatible with the RVC method. Find the RVC equivalent model!\")\n",
        "                    continue  # Continue searching for a valid file\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.getsize(file_path) > 100 * 1024 * 1024:  # Check file size in bytes (100MB)\n",
        "                    print(\"Skipping unusable training file:\", file)\n",
        "                    continue  # Continue searching for a valid file\n",
        "                return file_name\n",
        "    return None\n",
        "\n",
        "MODEL = find_pth_file(\"/content/unzips\")\n",
        "if MODEL is not None:\n",
        "    print(\"Found .pth file:\", MODEL + \".pth\")\n",
        "else:\n",
        "    print(\"Error: Could not find a valid .pth file within the extracted zip.\")\n",
        "    print(\"If there's an error above this talking about 'Access denied', try one of the Alt URLs in the Google Sheets for this model.\")\n",
        "    MODEL = \"\"\n",
        "    global condition3\n",
        "    condition3 = True\n",
        "\n",
        "index_path = \"\"\n",
        "\n",
        "def find_version_number(index_path):\n",
        "    if condition2 and not condition1:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "    filename = os.path.basename(index_path)\n",
        "\n",
        "    if filename.endswith(\"_v2.index\"):\n",
        "        return 'RVC v2'\n",
        "    elif filename.endswith(\"_v1.index\"):\n",
        "        return 'RVC v1'\n",
        "    else:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "if MODEL != \"\":\n",
        "    # Move model into logs folder\n",
        "    for root, dirs, files in os.walk('/content/unzips'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.endswith(\".index\"):\n",
        "                print(\"Found index file:\", file)\n",
        "                is_index_found = False\n",
        "                condition1 = True\n",
        "                logs_folder = os.path.join('/content/Mangio-RVC-Fork/logs', MODEL)\n",
        "                os.makedirs(logs_folder, exist_ok=True)  # Create the logs folder if it doesn't exist\n",
        "\n",
        "                # Delete identical .index file if it exists\n",
        "                if file.endswith(\".index\"):\n",
        "                    identical_index_path = os.path.join(logs_folder, file)\n",
        "                    if os.path.exists(identical_index_path):\n",
        "                        os.remove(identical_index_path)\n",
        "\n",
        "                shutil.move(file_path, logs_folder)\n",
        "                index_path = os.path.join(logs_folder, file)  # Set index_path variable\n",
        "\n",
        "            elif \"G_\" not in file and \"D_\" not in file and file.endswith(\".pth\"):\n",
        "                destination_path = f'/content/Mangio-RVC-Fork/weights/{MODEL}.pth'\n",
        "                if os.path.exists(destination_path):\n",
        "                    print(\"You already downloaded this model. Re-importing anyways..\")\n",
        "                shutil.move(file_path, destination_path)\n",
        "\n",
        "if condition1 is False:\n",
        "    logs_folder = os.path.join('/content/Mangio-RVC-Fork/logs', MODEL)\n",
        "    os.makedirs(logs_folder, exist_ok=True)\n",
        "# this is here so it doesnt crash if the model is missing an index for some reason\n",
        "else:\n",
        "    print(\"URL cannot be left empty. If you don't want to download a model now, just skip this step.\")\n",
        "\n",
        "# Качаем любой index-файл, если в архиве его не было\n",
        "if is_index_found is False:\n",
        "  logs_folder = os.path.join('/content/Mangio-RVC-Fork/logs', MODEL)\n",
        "  index_path = os.path.join(logs_folder, 'model.index')\n",
        "  if os.path.exists(index_path) == False:\n",
        "    !wget 'https://huggingface.co/sail-rvc/2001MJAIDAM/resolve/main/model.index' -P {logs_folder}\n",
        "\n",
        "!rm -r /content/unzips/\n",
        "!rm -r /content/zips/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0x6VOMyae_lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8CNwbOjZPUY"
      },
      "source": [
        "# Начинаем обработку исходника\n",
        "### В ***/content/input*** должен быть трек, а RVC-модель должна быть в репозитории ***/content/Mangio-RVC-Fork***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0XuTHvtDZJPT"
      },
      "outputs": [],
      "source": [
        "# @title #Отделяем вокал от минуса\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "\n",
        "from pathlib import Path, PurePath\n",
        "from IPython.display import Audio, display, HTML, FileLink\n",
        "import os\n",
        "\n",
        "# @markdown Папка с исходным музыкальным файлом (только один файл):\n",
        "INPUT = '/content/input' #@param {type:\"string\"}\n",
        "# @markdown ---\n",
        "OUTPUT_UVR_FOLDER = '/content/output_uvr' #@param {type:\"string\"}\n",
        "# @markdown ---\n",
        "# @markdown Соотношение скорость/качество (1 - максимальная скорость, 8 - максимальное качество):\n",
        "quaility = 8 #@param {type:\"slider\", min:1, max:8, step:1}\n",
        "\n",
        "BigShifts = 11\n",
        "overlap_InstVoc = quaility\n",
        "overlap_VitLarge = quaility\n",
        "weight_InstVoc = 8\n",
        "weight_VitLarge = 5\n",
        "use_VOCFT = True\n",
        "overlap_VOCFT = 0.1\n",
        "weight_VOCFT = 1\n",
        "vocals_instru_only = True\n",
        "overlap_demucs = 0.6\n",
        "output_format = 'PCM_16'\n",
        "vocals_only = ''\n",
        "use_VOCFT = ''\n",
        "if vocals_instru_only:\n",
        "    vocals_only = '--vocals_only true'\n",
        "else:\n",
        "    vocals_only = ''\n",
        "if use_VOCFT:\n",
        "    use_VOCFT = '--use_VOCFT true'\n",
        "else:\n",
        "    use_VOCFT = ''\n",
        "\n",
        "filename = next(Path(INPUT).glob('*.mp3'))\n",
        "INPUT_NAME = Path(filename).stem\n",
        "VOCAL_FILE = os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_vocals.wav\")\n",
        "INSTRUM_FILE = os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_instrum.wav\")\n",
        "\n",
        "!python inference.py \\\n",
        "      --large_gpu \\\n",
        "      --weight_InstVoc {weight_InstVoc} \\\n",
        "      --weight_VOCFT {weight_VOCFT} \\\n",
        "      --weight_VitLarge {weight_VitLarge} \\\n",
        "      --input_audio \"{filename}\" \\\n",
        "      --overlap_demucs {overlap_demucs} \\\n",
        "      --overlap_VOCFT {overlap_VOCFT} \\\n",
        "      --overlap_InstVoc {overlap_InstVoc} \\\n",
        "      --overlap_VitLarge {overlap_VitLarge} \\\n",
        "      --output_format {output_format} \\\n",
        "      --BigShifts {BigShifts} \\\n",
        "      --output_folder \"{OUTPUT_UVR_FOLDER}\" \\\n",
        "      {vocals_only} \\\n",
        "      {use_VOCFT}\n",
        "\n",
        "print(\"\\nПослушаем разделённый трек.\")\n",
        "print(\"Нужно немного подождать, сейчас появится...\")\n",
        "# колаб порой офигивает от размера wav и дисконнектится\n",
        "!ffmpeg -y -i {VOCAL_FILE} -vn -ar 44100 -ac 2 -b:a 192k {os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_vocals\")}.mp3 &> /dev/null\n",
        "!ffmpeg -y -i {INSTRUM_FILE} -vn -ar 44100 -ac 2 -b:a 192k {os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_instrum\")}.mp3 &> /dev/null\n",
        "print(\"Вокал:\")\n",
        "audio_vocal = Audio(os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_vocals.mp3\"), autoplay=False)\n",
        "display(audio_vocal)\n",
        "print(\"Инструментал:\")\n",
        "audio_inst = Audio(os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_instrum.mp3\"), autoplay=False)\n",
        "display(audio_inst)\n",
        "\n",
        "!rm -rf {os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_vocals.mp3\")}\n",
        "!rm -rf {os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_instrum.mp3\")}\n",
        "\n",
        "print('\\nСовет: если в вокале много эха и ревера, переходи к следующему шагу перед преобразованием RVC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3yztvPmFytx-"
      },
      "outputs": [],
      "source": [
        "%cd /content/Mangio-RVC-Fork\n",
        "# @title # Доп обработка от ревера и эхо (опционально)\n",
        "# @markdown ##### Новый файл автоматически заменит исходный вокальный файл /content/output_uvr/file_vocals.wav\n",
        "# @markdown ---\n",
        "# @markdown ##### Эти значения можно не трогать:\n",
        "\n",
        "postprocess = False #@param {type:\"boolean\"}\n",
        "tta = True #@param {type:\"boolean\"}\n",
        "is_half = False #@param {type:\"boolean\"}\n",
        "window_size = 512 # @param {type:\"slider\", min:0, max:1024, step:32}\n",
        "\n",
        "from pathlib import Path, PurePath\n",
        "from IPython.display import Audio, display, HTML, FileLink\n",
        "\n",
        "input_denoise_file = VOCAL_FILE\n",
        "output_folder = PurePath(VOCAL_FILE).parent\n",
        "\n",
        "import os, sys, torch, warnings, pdb\n",
        "\n",
        "now_dir = os.getcwd()\n",
        "sys.path.append(now_dir)\n",
        "from json import load as ll\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import librosa\n",
        "import importlib\n",
        "import numpy as np\n",
        "import hashlib, math\n",
        "from tqdm import tqdm\n",
        "from lib.uvr5_pack.lib_v5 import spec_utils\n",
        "from lib.uvr5_pack.utils import _get_name_params, inference\n",
        "from lib.uvr5_pack.lib_v5.model_param_init import ModelParameters\n",
        "import soundfile as sf\n",
        "from lib.uvr5_pack.lib_v5.nets_new import CascadedNet\n",
        "from lib.uvr5_pack.lib_v5 import nets_61968KB as nets\n",
        "\n",
        "class _audio_pre_new:\n",
        "    def __init__(self, agg, model_path, device, is_half):\n",
        "        self.model_path = model_path\n",
        "        self.device = device\n",
        "        self.data = {\n",
        "            # Processing Options\n",
        "            \"postprocess\": postprocess,\n",
        "            \"tta\": tta,\n",
        "            # Constants\n",
        "            \"window_size\": window_size,\n",
        "            \"agg\": agg,\n",
        "            \"high_end_process\": \"mirroring\",\n",
        "        }\n",
        "        mp = ModelParameters(\"lib/uvr5_pack/lib_v5/modelparams/4band_v3.json\")\n",
        "        nout = 64 if \"DeReverb\" in model_path else 48\n",
        "        model = CascadedNet(mp.param[\"bins\"] * 2, nout)\n",
        "        cpk = torch.load(model_path, map_location=\"cuda\")\n",
        "        model.load_state_dict(cpk)\n",
        "        model.eval()\n",
        "        if is_half:\n",
        "            model = model.half().to(device)\n",
        "        else:\n",
        "            model = model.to(device)\n",
        "\n",
        "        self.mp = mp\n",
        "        self.model = model\n",
        "\n",
        "    def _path_audio_(\n",
        "        self, music_file, vocal_root=None, ins_root=None, format=\"flac\"\n",
        "    ):\n",
        "        if ins_root is None and vocal_root is None:\n",
        "            return \"No save root.\"\n",
        "        name = os.path.basename(music_file)\n",
        "        if ins_root is not None:\n",
        "            os.makedirs(ins_root, exist_ok=True)\n",
        "        if vocal_root is not None:\n",
        "            os.makedirs(vocal_root, exist_ok=True)\n",
        "        X_wave, y_wave, X_spec_s, y_spec_s = {}, {}, {}, {}\n",
        "        bands_n = len(self.mp.param[\"band\"])\n",
        "        for d in range(bands_n, 0, -1):\n",
        "            bp = self.mp.param[\"band\"][d]\n",
        "            if d == bands_n:  # high-end band\n",
        "                (\n",
        "                    X_wave[d],\n",
        "                    _,\n",
        "                ) = librosa.core.load(\n",
        "                    music_file,\n",
        "                    bp[\"sr\"],\n",
        "                    False,\n",
        "                    dtype=np.float32,\n",
        "                    res_type=bp[\"res_type\"],\n",
        "                )\n",
        "                if X_wave[d].ndim == 1:\n",
        "                    X_wave[d] = np.asfortranarray([X_wave[d], X_wave[d]])\n",
        "            else:  # lower bands\n",
        "                X_wave[d] = librosa.core.resample(\n",
        "                    X_wave[d + 1],\n",
        "                    self.mp.param[\"band\"][d + 1][\"sr\"],\n",
        "                    bp[\"sr\"],\n",
        "                    res_type=bp[\"res_type\"],\n",
        "                )\n",
        "            # Stft of wave source\n",
        "            X_spec_s[d] = spec_utils.wave_to_spectrogram_mt(\n",
        "                X_wave[d],\n",
        "                bp[\"hl\"],\n",
        "                bp[\"n_fft\"],\n",
        "                self.mp.param[\"mid_side\"],\n",
        "                self.mp.param[\"mid_side_b2\"],\n",
        "                self.mp.param[\"reverse\"],\n",
        "            )\n",
        "            # pdb.set_trace()\n",
        "            if d == bands_n and self.data[\"high_end_process\"] != \"none\":\n",
        "                input_high_end_h = (bp[\"n_fft\"] // 2 - bp[\"crop_stop\"]) + (\n",
        "                    self.mp.param[\"pre_filter_stop\"] - self.mp.param[\"pre_filter_start\"]\n",
        "                )\n",
        "                input_high_end = X_spec_s[d][\n",
        "                    :, bp[\"n_fft\"] // 2 - input_high_end_h : bp[\"n_fft\"] // 2, :\n",
        "                ]\n",
        "\n",
        "        X_spec_m = spec_utils.combine_spectrograms(X_spec_s, self.mp)\n",
        "        aggresive_set = float(self.data[\"agg\"] / 100)\n",
        "        aggressiveness = {\n",
        "            \"value\": aggresive_set,\n",
        "            \"split_bin\": self.mp.param[\"band\"][1][\"crop_stop\"],\n",
        "        }\n",
        "        with torch.no_grad():\n",
        "            pred, X_mag, X_phase = inference(\n",
        "                X_spec_m, self.device, self.model, aggressiveness, self.data\n",
        "            )\n",
        "        # Postprocess\n",
        "        if self.data[\"postprocess\"]:\n",
        "            pred_inv = np.clip(X_mag - pred, 0, np.inf)\n",
        "            pred = spec_utils.mask_silence(pred, pred_inv)\n",
        "        y_spec_m = pred * X_phase\n",
        "        v_spec_m = X_spec_m - y_spec_m\n",
        "\n",
        "        if ins_root is not None:\n",
        "            if self.data[\"high_end_process\"].startswith(\"mirroring\"):\n",
        "                input_high_end_ = spec_utils.mirroring(\n",
        "                    self.data[\"high_end_process\"], y_spec_m, input_high_end, self.mp\n",
        "                )\n",
        "                wav_instrument = spec_utils.cmb_spectrogram_to_wave(\n",
        "                    y_spec_m, self.mp, input_high_end_h, input_high_end_\n",
        "                )\n",
        "            else:\n",
        "                wav_instrument = spec_utils.cmb_spectrogram_to_wave(y_spec_m, self.mp)\n",
        "            if format in [\"wav\", \"flac\"]:\n",
        "                sf.write(\n",
        "                    os.path.join(\n",
        "                        ins_root,\n",
        "                        \"denoised_{}.{}\".format(name, format),\n",
        "                    ),\n",
        "                    (np.array(wav_instrument) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "            else:\n",
        "                path = os.path.join(\n",
        "                    ins_root, \"denoised_{}.wav\".format(name)\n",
        "                )\n",
        "                sf.write(\n",
        "                    path,\n",
        "                    (np.array(wav_instrument) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "                if os.path.exists(path):\n",
        "                    os.system(\n",
        "                        \"ffmpeg -i %s -vn %s -q:a 2 -y\"\n",
        "                        % (path, path[:-4] + \".%s\" % format)\n",
        "                    )\n",
        "        if vocal_root is not None:\n",
        "            if self.data[\"high_end_process\"].startswith(\"mirroring\"):\n",
        "                input_high_end_ = spec_utils.mirroring(\n",
        "                    self.data[\"high_end_process\"], v_spec_m, input_high_end, self.mp\n",
        "                )\n",
        "                wav_vocals = spec_utils.cmb_spectrogram_to_wave(\n",
        "                    v_spec_m, self.mp, input_high_end_h, input_high_end_\n",
        "                )\n",
        "            else:\n",
        "                wav_vocals = spec_utils.cmb_spectrogram_to_wave(v_spec_m, self.mp)\n",
        "            if format in [\"wav\", \"flac\"]:\n",
        "                sf.write(\n",
        "                    os.path.join(\n",
        "                        vocal_root,\n",
        "                        \"vocal_{}_{}.{}\".format(name, self.data[\"agg\"], format),\n",
        "                    ),\n",
        "                    (np.array(wav_vocals) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "            else:\n",
        "                path = os.path.join(\n",
        "                    vocal_root, \"vocal_{}_{}.wav\".format(name, self.data[\"agg\"])\n",
        "                )\n",
        "                sf.write(\n",
        "                    path,\n",
        "                    (np.array(wav_vocals) * 32768).astype(\"int16\"),\n",
        "                    self.mp.param[\"sr\"],\n",
        "                )\n",
        "                if os.path.exists(path):\n",
        "                    os.system(\n",
        "                        \"ffmpeg -i %s -vn %s -q:a 2 -y\"\n",
        "                        % (path, path[:-4] + \".%s\" % format)\n",
        "                    )\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "model_path = \"uvr5_weights/UVR-DeEcho-DeReverb.pth\"\n",
        "pre_fun = _audio_pre_new(model_path=model_path, device=device, is_half=is_half, agg=10)\n",
        "pre_fun._path_audio_(input_denoise_file, None, output_folder, \"wav\")\n",
        "\n",
        "%mv {os.path.join(os.path.dirname(VOCAL_FILE), \"denoised_\" + os.path.basename(VOCAL_FILE)) + PurePath(VOCAL_FILE).suffix} {VOCAL_FILE}\n",
        "\n",
        "# колаб порой офигивает от размера wav и дисконнектится, поэтому mp3\n",
        "!ffmpeg -y -i {VOCAL_FILE} -vn -ar 44100 -ac 2 -b:a 192k {os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_vocals\")}.mp3 &> /dev/null\n",
        "audio = Audio(os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_vocals.mp3\"), autoplay=False)\n",
        "display(audio)\n",
        "\n",
        "!rm -rf {os.path.join(OUTPUT_UVR_FOLDER, INPUT_NAME + \"_vocals.mp3\")}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Преобразование файла и склейка с исходным инструменталом"
      ],
      "metadata": {
        "id": "H3OJWmYNuTuH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0JNWaDOoK0H",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # 🚀 Преобразование\n",
        "from IPython.display import Audio, display, HTML, FileLink\n",
        "from pathlib import Path, PurePath\n",
        "import os\n",
        "from decimal import Decimal\n",
        "\n",
        "result_path = \"/content/output_rvc\"\n",
        "result_name = \"rvc_result\"\n",
        "result_format = \"mp3\"\n",
        "\n",
        "RVC_RESULT_FILE = os.path.join(result_path, result_name + \".\" + result_format)\n",
        "rvc_result_filename = os.path.basename(RVC_RESULT_FILE)\n",
        "\n",
        "f0_method = \"rmvpe\"\n",
        "\n",
        "# @markdown ## <font color=greeb>Настройки не меняют тональность</font>\n",
        "\n",
        "# @markdown ### <b>Питч</b> (октава вверх, октава вниз, стандарт):\n",
        "transpositionMode = \"\\u0421\\u0442\\u0430\\u043D\\u0434\\u0430\\u0440\\u0442\\u043D\\u044B\\u0439\" # @param [\"М -> Ж\", \"Ж -> М\", \"Стандартный\"]\n",
        "transposition = 0\n",
        "\n",
        "if transpositionMode == \"М -> Ж\":\n",
        "  transposition = 12\n",
        "elif transpositionMode == \"Ж -> М\":\n",
        "  transposition = -12\n",
        "elif transpositionMode == \"Стандартный\":\n",
        "  transposition = 0\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## Режим:\n",
        "mode = \"\\u0421\\u0442\\u0430\\u043D\\u0434\\u0430\\u0440\\u0442\\u043D\\u044B\\u0439\" # @param [\"М -> Ж\", \"Ж -> М\", \"Стандартный\", \"Ручная настройка\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### <b>Ручные настройки:</b>\n",
        "# @markdown ###### (не работает, если не выбран режим <b>Ручная настройка</b>)\n",
        "# @markdown ##### Quefrency (default 0.0 ms):\n",
        "quefrency = 0 # @param {type:\"slider\", min:0.0, max:2, step:0.1}\n",
        "# @markdown ##### Tembre factor (default 1.0):\n",
        "tembre = 1 # @param {type:\"slider\", min:0.0, max:2, step:0.1}\n",
        "\n",
        "if mode == \"М -> Ж\":\n",
        "  quefrency = 0.5\n",
        "  tembre = 1.3\n",
        "elif mode == \"Ж -> М\":\n",
        "  quefrency = 1.0\n",
        "  tembre = 0.7\n",
        "elif mode == \"Стандартный\":\n",
        "  quefrency = 0.0\n",
        "  tembre = 1.0\n",
        "\n",
        "# @markdown ### <i>Стандартный режим быстрее! Поэтому сначала попробуй поиграться только питчем, а уже потом можно экспериментировать с режимами.</i>\n",
        "# @markdown ---\n",
        "# @markdown ## <font color=grey>Подсказка:</font>\n",
        "# @markdown ###### <font color=grey>Из женского в мужской: quefrency = 1.0 (больше дефолтного), tembre = 0.7 (меньше дефолтного):</font>\n",
        "# @markdown ###### <font color=grey>Из мужского в женский: quefrency = 0.5 (чуть-чуть больше дефолтного), tembre = 1.3 (больше дефолтного):</font>\n",
        "# @markdown ###### <font color=grey>Универсальных решений нет, в первую очередь зависит от исходного голоса и конечной модели. Отталкиваться следует от значений выше.:</font>\n",
        "%cd /content/Mangio-RVC-Fork\n",
        "\n",
        "# \"\\n    arg 1) model name with .pth in ./weights: mi-test.pth\"\n",
        "# \"\\n    arg 2) source audio path: myFolder\\\\MySource.wav\"\n",
        "# \"\\n    arg 3) output file name to be placed in './audio-outputs': MyTest.wav\"\n",
        "# \"\\n    arg 4) feature index file path: logs/mi-test/added_IVF3042_Flat_nprobe_1.index\"\n",
        "# \"\\n    arg 5) speaker id: 0\"\n",
        "# \"\\n    arg 6) transposition: 0\"\n",
        "# \"\\n    arg 7) f0 method: harvest (pm, harvest, crepe, crepe-tiny, hybrid[x,x,x,x], mangio-crepe, mangio-crepe-tiny, rmvpe)\"\n",
        "# \"\\n    arg 8) crepe hop length: 160\"\n",
        "# \"\\n    arg 9) harvest median filter radius: 3 (0-7)\"\n",
        "# \"\\n    arg 10) post resample rate: 0\"\n",
        "# \"\\n    arg 11) mix volume envelope: 1\"\n",
        "# \"\\n    arg 12) feature index ratio: 0.78 (0-1)\"\n",
        "# \"\\n    arg 13) Voiceless Consonant Protection (Less Artifact): 0.33 (Smaller number = more protection. 0.50 means Dont Use.)\"\n",
        "# \"\\n    arg 14) Whether to formant shift the inference audio before conversion: False (if set to false, you can ignore setting the quefrency and timbre values for formanting)\"\n",
        "# \"\\n    arg 15)* Quefrency for formanting: 8.0 (no need to set if arg14 is False/false)\"\n",
        "# \"\\n    arg 16)* Timbre for formanting: 1.2 (no need to set if arg14 is False/false) \\n\"\n",
        "# \"\\nExample: mi-test.pth audios/Sidney.wav myTest.wav logs/mi-test/added_index.index 0 -2 harvest 160 3 0 1 0.95 0.33 0.45 True 8.0 1.2\"\n",
        "is_formant = \"False\"\n",
        "if quefrency != 0 and tembre != 1:\n",
        "  is_formant = \"True\"\n",
        "\n",
        "quefrency_value = \"{:.1f}\".format(Decimal(quefrency).quantize(Decimal('0.1')))\n",
        "tembre_value = \"{:.1f}\".format(Decimal(tembre).quantize(Decimal('0.1')))\n",
        "transposition_value = str(transposition)\n",
        "\n",
        "cmd = MODEL + \".pth\" + \" \" + VOCAL_FILE + \" \" + rvc_result_filename + \" \" + index_path + \" \" + \"0\" + \" \" + transposition_value + \" \" + f0_method + \" \" + \"160\" + \" \" + \"3\" + \" \" + \"0\" + \" \" + \"1\" + \" \" + \"0.78\" + \" \" + \"0.33\" + \" \" + \"0.45\" + \" \" + is_formant + \" \" + quefrency_value + \" \" + tembre_value\n",
        "print(cmd)\n",
        "!echo -e -n \"go infer\\n{cmd}\\nstop_infer\" | python3 infer-web.py --colab --pycmd python3 --is_cli &> /dev/null\n",
        "%mv /content/Mangio-RVC-Fork/audio-outputs/{rvc_result_filename} {RVC_RESULT_FILE}\n",
        "audio = Audio(RVC_RESULT_FILE, autoplay=False)\n",
        "display(audio)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "# @title # Пост-обработка\n",
        "# @markdown ### Компрессор + нормализация + лёгкая реверберация + разведение по стерео-панораме\n",
        "\n",
        "from IPython.display import Audio, display, HTML, FileLink\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "OUTPUT_PATH = '/content/output'\n",
        "PROCESSED_OUTPUT_FORMAT = 'mp3'\n",
        "COMPRESSED_RESULT_FILE = os.path.join(OUTPUT_PATH, f\"{os.path.splitext(RVC_RESULT_FILE)[0]}_compressed.{PROCESSED_OUTPUT_FORMAT}\")\n",
        "PROCESSED_RESULT_FILE = os.path.join(OUTPUT_PATH, f\"{os.path.splitext(RVC_RESULT_FILE)[0]}_processed.{PROCESSED_OUTPUT_FORMAT}\")\n",
        "\n",
        "# компрессируем вокал\n",
        "!ffmpeg -y -i {RVC_RESULT_FILE} -filter_complex \"anlmdn=s=10,acompressor=threshold=-20dB:ratio=4:attack=20:release=200,volume=2,loudnorm=I=-13:TP=-1.0:LRA=9,volume=1.5\" {COMPRESSED_RESULT_FILE}\n",
        "if os.path.isfile(COMPRESSED_RESULT_FILE) != True:\n",
        "  print(f\"Не удалось обработать файл {RVC_RESULT_FILE}\")\n",
        "  shutil.copy(RVC_RESULT_FILE, PROCESSED_RESULT_FILE)\n",
        "else:\n",
        "  if os.path.isfile(IMPULSE_FILE):\n",
        "    # добавление реверберации с разной обработкой для левого и правого канала для стереоскопического эффекта\n",
        "    print(\"Добавление реверберации с разной обработкой для левого и правого канала для стереоскопического эффекта\")\n",
        "    !ffmpeg -y -i {COMPRESSED_RESULT_FILE} -i {IMPULSE_FILE} -filter_complex \"[0:a]asplit=2[splita][splitb]; [splita]adelay=40|40[splita_delayed]; [splitb]adelay=20|20[splitb_delayed]; [splita_delayed][1]afir=dry=10:wet=10[reverb_left]; [splitb_delayed][1]afir=dry=10:wet=10[reverb_right]; [reverb_left][reverb_right]amerge=inputs=2[reverb]; [0:a][reverb]amix=inputs=2:weights=20 1[audio]\" -map \"[audio]\" {PROCESSED_RESULT_FILE}\n",
        "    if os.path.isfile(PROCESSED_RESULT_FILE):\n",
        "      !rm -rf {COMPRESSED_RESULT_FILE}\n",
        "    else:\n",
        "      print(f\"Не удалось обработать компрессированный файл {COMPRESSED_RESULT_FILE}\")\n",
        "      shutil.move(COMPRESSED_RESULT_FILE, PROCESSED_RESULT_FILE)\n",
        "  else:\n",
        "    print(f\"Не найден файл импульса: {IMPULSE_FILE}\")\n",
        "    shutil.move(COMPRESSED_RESULT_FILE, PROCESSED_RESULT_FILE)\n",
        "\n",
        "audio = Audio(PROCESSED_RESULT_FILE, autoplay=False)\n",
        "display(audio)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IzIpIvLUxWmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "# @title # Склейка\n",
        "\n",
        "from IPython.display import Audio, display, HTML, FileLink\n",
        "import os\n",
        "\n",
        "OUTPUT_PATH = '/content/output' #@param {type:\"string\"}\n",
        "OUTPUT_FORMAT = 'mp3'\n",
        "\n",
        "RESULT_FILE = os.path.join(OUTPUT_PATH, INPUT_NAME + \".\" + OUTPUT_FORMAT)\n",
        "\n",
        "!ffmpeg -y -i {PROCESSED_RESULT_FILE} -i {INSTRUM_FILE} -filter_complex \"[0:a][1:a]amerge=inputs=2[a]\" -map \"[a]\" -ac 2 {RESULT_FILE}\n",
        "\n",
        "audio = Audio(RESULT_FILE, autoplay=False)\n",
        "display(audio)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Xp05zq7DgcvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Готово\n",
        "#### Теперь можешь вернуться к любому предыдущему шагу, без необходимости запуска полного флоу. Например, можно загрузить другую модель, останется только выполнить преобразование вокала, который уже отделен от инструментала."
      ],
      "metadata": {
        "id": "Tr6iEhD2fi0d"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
